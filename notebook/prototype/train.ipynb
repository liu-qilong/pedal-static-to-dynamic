{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from src.tool import config\n",
    "from src import dataset, dataloader, model, loss, metric, optimizer\n",
    "from src.tool.registry import DATASET_REGISTRY, DATALOADER_REGISTRY, MODEL_REGISTRY, LOSS_REGISTRY, METRIC_REGISTRY, OPTIMIZER_REGISTRY\n",
    "\n",
    "# torch settings\n",
    "torch.manual_seed(0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CfgNode({'data': CfgNode({'dataset': 'Pedar_Dataset_static2dynamic', 'dataloader': 'DataLoader', 'train_ratio': 0.8, 'batch_size': 32}), 'model': CfgNode({'name': 'MLP'}), 'train': CfgNode({'loss': 'MSELoss', 'metric': '', 'optimizer': 'SGD', 'lr': 0.1, 'epoch': 100})})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load options\n",
    "path = '../../experiment/20210615/'\n",
    "opt = config.load_config(path)\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'Pedar_Dataset_static2dynamic',\n",
       " 'dataloader': 'DataLoader',\n",
       " 'train_ratio': 0.8,\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(opt.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 60)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "dataset = DATASET_REGISTRY[opt.data.dataset](static_path='output/pedar_static.pkl', dynamic_path='output/pedar_dynamic.pkl')\n",
    "train_dataset, test_dataset = random_split(dataset, [0.8, 0.2])\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DATALOADER_REGISTRY[opt.data.dataloader](train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DATALOADER_REGISTRY[opt.data.dataloader](test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & testing scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def train_step(\n",
    "        model: torch.nn.Module, \n",
    "        dataloader: torch.utils.data.DataLoader, \n",
    "        loss_fn: torch.nn.Module, \n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        device: torch.device) -> Tuple[float, float]:\n",
    "    # put model in train mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # send data to device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item() \n",
    "\n",
    "        # loss backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # return metric\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(\n",
    "        model: torch.nn.Module, \n",
    "        dataloader: torch.utils.data.DataLoader, \n",
    "        loss_fn: torch.nn.Module,\n",
    "        device: torch.device) -> Tuple[float, float]:\n",
    "    # put model in eval mode\n",
    "    model.eval() \n",
    "    test_loss = 0\n",
    "\n",
    "    # turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # send data to target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            test_pred_logits = model(X)\n",
    "\n",
    "            # loss calculation\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    # return metric\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train(\n",
    "        model: torch.nn.Module, \n",
    "        train_dataloader: torch.utils.data.DataLoader, \n",
    "        test_dataloader: torch.utils.data.DataLoader, \n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        loss_fn: torch.nn.Module,\n",
    "        epochs: int,\n",
    "        device: torch.device) -> Dict[str, List]:\n",
    "    # create results dict\n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"test_loss\": [],\n",
    "    }\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss = train_step(\n",
    "            model=model,\n",
    "            dataloader=train_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            )\n",
    "        \n",
    "        test_loss = test_step(\n",
    "            model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn,\n",
    "            device=device,\n",
    "            )\n",
    "\n",
    "        # logs\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "        )\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a45168a0e8441429534478f86271a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.1689 | test_loss: 0.1638 | \n",
      "Epoch: 2 | train_loss: 0.1581 | test_loss: 0.1532 | \n",
      "Epoch: 3 | train_loss: 0.1478 | test_loss: 0.1432 | \n",
      "Epoch: 4 | train_loss: 0.1380 | test_loss: 0.1340 | \n",
      "Epoch: 5 | train_loss: 0.1289 | test_loss: 0.1251 | \n",
      "Epoch: 6 | train_loss: 0.1206 | test_loss: 0.1170 | \n",
      "Epoch: 7 | train_loss: 0.1124 | test_loss: 0.1092 | \n",
      "Epoch: 8 | train_loss: 0.1049 | test_loss: 0.1020 | \n",
      "Epoch: 9 | train_loss: 0.0981 | test_loss: 0.0951 | \n",
      "Epoch: 10 | train_loss: 0.0913 | test_loss: 0.0889 | \n",
      "Epoch: 11 | train_loss: 0.0852 | test_loss: 0.0829 | \n",
      "Epoch: 12 | train_loss: 0.0796 | test_loss: 0.0775 | \n",
      "Epoch: 13 | train_loss: 0.0744 | test_loss: 0.0723 | \n",
      "Epoch: 14 | train_loss: 0.0694 | test_loss: 0.0675 | \n",
      "Epoch: 15 | train_loss: 0.0648 | test_loss: 0.0632 | \n",
      "Epoch: 16 | train_loss: 0.0607 | test_loss: 0.0591 | \n",
      "Epoch: 17 | train_loss: 0.0565 | test_loss: 0.0552 | \n",
      "Epoch: 18 | train_loss: 0.0531 | test_loss: 0.0517 | \n",
      "Epoch: 19 | train_loss: 0.0496 | test_loss: 0.0484 | \n",
      "Epoch: 20 | train_loss: 0.0464 | test_loss: 0.0454 | \n",
      "Epoch: 21 | train_loss: 0.0436 | test_loss: 0.0426 | \n",
      "Epoch: 22 | train_loss: 0.0408 | test_loss: 0.0400 | \n",
      "Epoch: 23 | train_loss: 0.0383 | test_loss: 0.0376 | \n",
      "Epoch: 24 | train_loss: 0.0360 | test_loss: 0.0353 | \n",
      "Epoch: 25 | train_loss: 0.0340 | test_loss: 0.0333 | \n",
      "Epoch: 26 | train_loss: 0.0319 | test_loss: 0.0313 | \n",
      "Epoch: 27 | train_loss: 0.0301 | test_loss: 0.0296 | \n",
      "Epoch: 28 | train_loss: 0.0283 | test_loss: 0.0279 | \n",
      "Epoch: 29 | train_loss: 0.0268 | test_loss: 0.0264 | \n",
      "Epoch: 30 | train_loss: 0.0254 | test_loss: 0.0250 | \n",
      "Epoch: 31 | train_loss: 0.0240 | test_loss: 0.0237 | \n",
      "Epoch: 32 | train_loss: 0.0227 | test_loss: 0.0225 | \n",
      "Epoch: 33 | train_loss: 0.0216 | test_loss: 0.0213 | \n",
      "Epoch: 34 | train_loss: 0.0204 | test_loss: 0.0202 | \n",
      "Epoch: 35 | train_loss: 0.0194 | test_loss: 0.0193 | \n",
      "Epoch: 36 | train_loss: 0.0186 | test_loss: 0.0184 | \n",
      "Epoch: 37 | train_loss: 0.0176 | test_loss: 0.0175 | \n",
      "Epoch: 38 | train_loss: 0.0167 | test_loss: 0.0167 | \n",
      "Epoch: 39 | train_loss: 0.0160 | test_loss: 0.0159 | \n",
      "Epoch: 40 | train_loss: 0.0152 | test_loss: 0.0152 | \n",
      "Epoch: 41 | train_loss: 0.0146 | test_loss: 0.0146 | \n",
      "Epoch: 42 | train_loss: 0.0140 | test_loss: 0.0140 | \n",
      "Epoch: 43 | train_loss: 0.0134 | test_loss: 0.0134 | \n",
      "Epoch: 44 | train_loss: 0.0129 | test_loss: 0.0128 | \n",
      "Epoch: 45 | train_loss: 0.0123 | test_loss: 0.0123 | \n",
      "Epoch: 46 | train_loss: 0.0118 | test_loss: 0.0119 | \n",
      "Epoch: 47 | train_loss: 0.0114 | test_loss: 0.0114 | \n",
      "Epoch: 48 | train_loss: 0.0109 | test_loss: 0.0110 | \n",
      "Epoch: 49 | train_loss: 0.0105 | test_loss: 0.0106 | \n",
      "Epoch: 50 | train_loss: 0.0101 | test_loss: 0.0102 | \n",
      "Epoch: 51 | train_loss: 0.0098 | test_loss: 0.0098 | \n",
      "Epoch: 52 | train_loss: 0.0094 | test_loss: 0.0095 | \n",
      "Epoch: 53 | train_loss: 0.0091 | test_loss: 0.0092 | \n",
      "Epoch: 54 | train_loss: 0.0089 | test_loss: 0.0089 | \n",
      "Epoch: 55 | train_loss: 0.0085 | test_loss: 0.0086 | \n",
      "Epoch: 56 | train_loss: 0.0083 | test_loss: 0.0083 | \n",
      "Epoch: 57 | train_loss: 0.0080 | test_loss: 0.0081 | \n",
      "Epoch: 58 | train_loss: 0.0078 | test_loss: 0.0078 | \n",
      "Epoch: 59 | train_loss: 0.0075 | test_loss: 0.0076 | \n",
      "Epoch: 60 | train_loss: 0.0073 | test_loss: 0.0074 | \n",
      "Epoch: 61 | train_loss: 0.0071 | test_loss: 0.0071 | \n",
      "Epoch: 62 | train_loss: 0.0069 | test_loss: 0.0070 | \n",
      "Epoch: 63 | train_loss: 0.0067 | test_loss: 0.0068 | \n",
      "Epoch: 64 | train_loss: 0.0065 | test_loss: 0.0066 | \n",
      "Epoch: 65 | train_loss: 0.0063 | test_loss: 0.0064 | \n",
      "Epoch: 66 | train_loss: 0.0062 | test_loss: 0.0063 | \n",
      "Epoch: 67 | train_loss: 0.0060 | test_loss: 0.0061 | \n",
      "Epoch: 68 | train_loss: 0.0059 | test_loss: 0.0059 | \n",
      "Epoch: 69 | train_loss: 0.0058 | test_loss: 0.0058 | \n",
      "Epoch: 70 | train_loss: 0.0056 | test_loss: 0.0057 | \n",
      "Epoch: 71 | train_loss: 0.0055 | test_loss: 0.0055 | \n",
      "Epoch: 72 | train_loss: 0.0054 | test_loss: 0.0054 | \n",
      "Epoch: 73 | train_loss: 0.0053 | test_loss: 0.0053 | \n",
      "Epoch: 74 | train_loss: 0.0051 | test_loss: 0.0052 | \n",
      "Epoch: 75 | train_loss: 0.0050 | test_loss: 0.0051 | \n",
      "Epoch: 76 | train_loss: 0.0049 | test_loss: 0.0050 | \n",
      "Epoch: 77 | train_loss: 0.0048 | test_loss: 0.0049 | \n",
      "Epoch: 78 | train_loss: 0.0047 | test_loss: 0.0048 | \n",
      "Epoch: 79 | train_loss: 0.0046 | test_loss: 0.0047 | \n",
      "Epoch: 80 | train_loss: 0.0045 | test_loss: 0.0046 | \n",
      "Epoch: 81 | train_loss: 0.0045 | test_loss: 0.0045 | \n",
      "Epoch: 82 | train_loss: 0.0044 | test_loss: 0.0044 | \n",
      "Epoch: 83 | train_loss: 0.0043 | test_loss: 0.0044 | \n",
      "Epoch: 84 | train_loss: 0.0042 | test_loss: 0.0043 | \n",
      "Epoch: 85 | train_loss: 0.0042 | test_loss: 0.0042 | \n",
      "Epoch: 86 | train_loss: 0.0041 | test_loss: 0.0041 | \n",
      "Epoch: 87 | train_loss: 0.0041 | test_loss: 0.0041 | \n",
      "Epoch: 88 | train_loss: 0.0040 | test_loss: 0.0040 | \n",
      "Epoch: 89 | train_loss: 0.0039 | test_loss: 0.0039 | \n",
      "Epoch: 90 | train_loss: 0.0038 | test_loss: 0.0039 | \n",
      "Epoch: 91 | train_loss: 0.0038 | test_loss: 0.0038 | \n",
      "Epoch: 92 | train_loss: 0.0038 | test_loss: 0.0038 | \n",
      "Epoch: 93 | train_loss: 0.0037 | test_loss: 0.0037 | \n",
      "Epoch: 94 | train_loss: 0.0036 | test_loss: 0.0037 | \n",
      "Epoch: 95 | train_loss: 0.0035 | test_loss: 0.0036 | \n",
      "Epoch: 96 | train_loss: 0.0036 | test_loss: 0.0036 | \n",
      "Epoch: 97 | train_loss: 0.0035 | test_loss: 0.0035 | \n",
      "Epoch: 98 | train_loss: 0.0034 | test_loss: 0.0035 | \n",
      "Epoch: 99 | train_loss: 0.0034 | test_loss: 0.0034 | \n",
      "Epoch: 100 | train_loss: 0.0033 | test_loss: 0.0034 | \n"
     ]
    }
   ],
   "source": [
    "model = MODEL_REGISTRY[opt.model.name](hidden_size=256).to(device)\n",
    "loss = LOSS_REGISTRY[opt.train.loss]()\n",
    "optimizer = OPTIMIZER_REGISTRY[opt.train.optimizer](params=model.parameters(), lr=opt.train.lr)\n",
    "\n",
    "results = train(model, train_dataloader, test_dataloader, optimizer, loss, opt.train.epoch, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
